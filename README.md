# VQA: Privacy-Preserving Visual Question Answering with Token Pruning and Mixing

This project proposes a methodology that combines **Token Pruning** and **Token Mixing** techniques to enhance the **Privacy Robustness** of VQA models while minimizing performance degradation.

## ğŸ¯ Metric

We use **Membership Inference Attack (MIA)** techniques to quantitatively evaluate Privacy Robustness.

- Loss based MIA
- Confidence based MIA
- Difficulty Calibration Attack
- RAPID

### Evaluation Metrics
- **Attack Accuracy**: Accuracy of MIA (lower is better for privacy)
- **Precision/Recall**: Member detection performance
- **ROC-AUC**: Overall attack performance
- **PR-AUC**: Area under Precision-Recall curve

---

## ğŸ›¡ï¸ Comparative Defense Techniques

- DP-SGD (Differentially Private Stochastic Gradient Descent)

---

## ğŸš€ Usage

### 1. Download
```bash
pip install -r requirements.txt
```

### 2. Dataset
COCO-QA dataset:
```
cocoqa/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ questions.json
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ questions.json
â””â”€â”€ labels.txt
```

### 3. Train
```bash
# Token Pruning + DP-SGD
python train.py -c ./examples/cfg.yaml

# Train without DP-SGD
python train.py -c ./examples/cfg.yaml --use_dp_sgd false
```

### 4. Test
```bash
python test.py -c ./examples/cfg.yaml -w ./checkpoints/best_model.pth
```

### 5. Privacy Evaluation
```bash
# Difficulty Calibration Attack
python ./attack/calibration.py -c ./examples/cfg.yaml -w ./checkpoints/best_model.pth

# RAPID Attack (Metric-based)
python ./attack/rapid.py -c ./examples/cfg.yaml -w ./checkpoints/best_model.pth --shadow_models blip,vilt,git
```

---

## âš¡ Hyperparameter Optimization

### Multi-Objective Optimization with Optuna
**File**: `optuna_tune.py`

Using the **Optuna** framework, we simultaneously optimize two objectives:
1. **Maximize Accuracy**: Improve VQA performance
2. **Minimize MIA Attack Accuracy**: Enhance privacy robustness

**Usage:**
```bash
python optuna_tune.py -c ./examples/optuna.yaml --n_trials 50
```

---

## ğŸ“ Structure

```
VQA/
â”œâ”€â”€ train.py              # Model training script
â”œâ”€â”€ test.py               # Model evaluation script
â”œâ”€â”€ optuna_tune.py        # Hyperparameter optimization
â”œâ”€â”€ requirements.txt      # Dependencies
â”œâ”€â”€ data/
â”‚   â””â”€â”€ data.py          # Dataset class
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ model.py         # VQA model definition
â”‚   â”œâ”€â”€ vision_encoder.py
â”‚   â””â”€â”€ text_encoder.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ fusion.py        # Token Pruning & Mixing implementation
â”‚   â”œâ”€â”€ src.py           # Training/validation functions
â”‚   â””â”€â”€ util.py          # Utility functions
â”œâ”€â”€ attack/
â”‚   â”œâ”€â”€ calibration.py   # Difficulty Calibration Attack
â”‚   â”œâ”€â”€ rapid.py         # Metric-based Attack (RAPID)
â”‚   â”œâ”€â”€ metric_src.py    # Common evaluation functions
â”‚   â””â”€â”€ cali_src.py      # Calibration utilities
â””â”€â”€ examples/
    â”œâ”€â”€ cfg.yaml         # Configuration file example
    â””â”€â”€ optuna.yaml      # Optuna configuration example
```

---