{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a16e9693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Penguin\\anaconda3\\envs\\vqa\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from model import VQAModel\n",
    "\n",
    "HF_HUB_DISABLE_SYMLINKS_WARNING =1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e905b8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "--- 1. 더미 데이터 생성 중... ---\n",
      "Dummy Images shape: torch.Size([4, 3, 224, 224])\n",
      "Dummy 'input_ids' shape: torch.Size([4, 12])\n",
      "Dummy 'attention_mask' shape: torch.Size([4, 12])\n"
     ]
    }
   ],
   "source": [
    "# 1. 테스트용 하이퍼파라미터 설정\n",
    "BATCH_SIZE = 4\n",
    "IMG_SIZE = 224\n",
    "SEQ_LEN = 12   # DataLoader 테스트 시 출력된 최대 길이 (예시)\n",
    "NUM_CLASSES = 13 # DataLoader 테스트 시 출력된 고유 답변 수\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. 더미 데이터 생성 (DataLoader의 출력 모방)\n",
    "print(\"\\n--- 1. 더미 데이터 생성 중... ---\")\n",
    "\n",
    "# (1) 이미지 배치\n",
    "# Shape: (B, C, H, W), Type: float\n",
    "dummy_images = torch.randn(BATCH_SIZE, 3, IMG_SIZE, IMG_SIZE).to(device)\n",
    "print(f\"Dummy Images shape: {dummy_images.shape}\")\n",
    "\n",
    "# (2) 텍스트 입력 배치 (BatchEncoding 딕셔너리 모방)\n",
    "# Shape: (B, L), Type: long (BERT vocab 인덱스)\n",
    "# 0(PAD), 101(CLS), 102(SEP) 외의 임의의 인덱스 사용\n",
    "dummy_input_ids = torch.randint(low=1000, high=30000, \n",
    "                                size=(BATCH_SIZE, SEQ_LEN), \n",
    "                                dtype=torch.long).to(device)\n",
    "\n",
    "# Shape: (B, L), Type: long\n",
    "dummy_attention_mask = torch.ones(BATCH_SIZE, SEQ_LEN, dtype=torch.long).to(device)\n",
    "\n",
    "# 실제 DataLoader 출력과 유사하게 딕셔너리로 묶기 (필수는 아님)\n",
    "dummy_inputs = {\n",
    "    'input_ids': dummy_input_ids,\n",
    "    'attention_mask': dummy_attention_mask\n",
    "}\n",
    "print(f\"Dummy 'input_ids' shape: {dummy_inputs['input_ids'].shape}\")\n",
    "print(f\"Dummy 'attention_mask' shape: {dummy_inputs['attention_mask'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "066e4933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2. 모델('attention' 퓨전) 순전파 테스트 ---\n",
      "\n",
      "[성공] 'attention' 모델 출력 shape: torch.Size([4, 13])\n",
      "  (예상 shape: (4, 13))\n",
      "\n",
      "--- 3. 모델('concat' 퓨전) 순전파 테스트 ---\n",
      "\n",
      "[성공] 'concat' 모델 출력 shape: torch.Size([4, 13])\n",
      "  (예상 shape: (4, 13))\n"
     ]
    }
   ],
   "source": [
    "# 3. 모델 초기화 및 테스트 (Attention 퓨전 사용)\n",
    "print(\"\\n--- 2. 모델('attention' 퓨전) 순전파 테스트 ---\")\n",
    "\n",
    "# ★ num_classes를 실제 값(13)으로 설정\n",
    "try:\n",
    "    model = VQAModel(\n",
    "        fusion_type=\"attention\", \n",
    "        num_classes=NUM_CLASSES\n",
    "    ).to(device)\n",
    "    \n",
    "    model.train() # (BatchNorm, Dropout을 위해 .train() 모드)\n",
    "\n",
    "    # 모델 순전파\n",
    "    # \n",
    "    output = model(\n",
    "        images=dummy_images, \n",
    "        input_ids=dummy_inputs['input_ids'], \n",
    "        attention_mask=dummy_inputs['attention_mask']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n[성공] 'attention' 모델 출력 shape: {output.shape}\")\n",
    "    print(f\"  (예상 shape: ({BATCH_SIZE}, {NUM_CLASSES}))\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n[실패] 'attention' 모델 테스트 중 오류 발생: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# 4. 모델 초기화 및 테스트 (Concat 퓨전 사용)\n",
    "print(\"\\n--- 3. 모델('concat' 퓨전) 순전파 테스트 ---\")\n",
    "\n",
    "try:\n",
    "    model_concat = VQAModel(\n",
    "        fusion_type=\"concat\", \n",
    "        num_classes=NUM_CLASSES\n",
    "    ).to(device)\n",
    "    \n",
    "    model_concat.train()\n",
    "    \n",
    "    # 모델 순전파\n",
    "    output_concat = model_concat(\n",
    "        images=dummy_images, \n",
    "        input_ids=dummy_inputs['input_ids'], \n",
    "        attention_mask=dummy_inputs['attention_mask']\n",
    "    )\n",
    "\n",
    "    print(f\"\\n[성공] 'concat' 모델 출력 shape: {output_concat.shape}\")\n",
    "    print(f\"  (예상 shape: ({BATCH_SIZE}, {NUM_CLASSES}))\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n[실패] 'concat' 모델 테스트 중 오류 발생: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
